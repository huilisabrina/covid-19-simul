monte_carlo_sim.bash: line 9: cd: /home/ubuntu/CS205_FinalProject/testing: No such file or directory
Begin simulation: 1
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-a81d7ee4-d091-468c-a209-8503fb188bd2;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 691ms :: artifacts dl 18ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-a81d7ee4-d091-468c-a209-8503fb188bd2
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/29ms)
20/05/11 05:40:18 INFO SparkContext: Running Spark version 2.4.4
20/05/11 05:40:18 INFO SparkContext: Submitted application: cluster_run
20/05/11 05:40:19 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 05:40:19 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 05:40:19 INFO SecurityManager: Changing view acls groups to: 
20/05/11 05:40:19 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 05:40:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 05:40:20 INFO Utils: Successfully started service 'sparkDriver' on port 45131.
20/05/11 05:40:20 INFO SparkEnv: Registering MapOutputTracker
20/05/11 05:40:20 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 05:40:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 05:40:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 05:40:20 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-36f0f191-88fc-4c43-8d8e-c5d3bfb5ffd8
20/05/11 05:40:20 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 05:40:20 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 05:40:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 05:40:21 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 05:40:22 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 05:40:23 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 05:40:24 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 05:40:24 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 05:40:24 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 05:40:24 INFO Client: Setting up container launch context for our AM
20/05/11 05:40:24 INFO Client: Setting up the launch environment for our AM container
20/05/11 05:40:24 INFO Client: Preparing resources for our AM container
20/05/11 05:40:24 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 05:40:30 INFO Client: Uploading resource file:/mnt/tmp/spark-a40fa2ef-d47a-4ad9-8094-72a63820483c/__spark_libs__3543704306317151149.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0010/__spark_libs__3543704306317151149.zip
20/05/11 05:40:33 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0010/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 05:40:33 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0010/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 05:40:33 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0010/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 05:40:33 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0010/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 05:40:33 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0010/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 05:40:33 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0010/pyspark.zip
20/05/11 05:40:33 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0010/py4j-0.10.7-src.zip
20/05/11 05:40:33 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 05:40:33 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 05:40:33 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 05:40:33 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 05:40:33 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 05:40:33 INFO Client: Uploading resource file:/mnt/tmp/spark-a40fa2ef-d47a-4ad9-8094-72a63820483c/__spark_conf__8174560600415964699.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0010/__spark_conf__.zip
20/05/11 05:40:34 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 05:40:34 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 05:40:34 INFO SecurityManager: Changing view acls groups to: 
20/05/11 05:40:34 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 05:40:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 05:40:37 INFO Client: Submitting application application_1589148979959_0010 to ResourceManager
20/05/11 05:40:37 INFO YarnClientImpl: Submitted application application_1589148979959_0010
20/05/11 05:40:37 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0010 and attemptId None
20/05/11 05:40:38 INFO Client: Application report for application_1589148979959_0010 (state: ACCEPTED)
20/05/11 05:40:38 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589175637849
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0010/
	 user: hadoop
20/05/11 05:40:39 INFO Client: Application report for application_1589148979959_0010 (state: ACCEPTED)
20/05/11 05:40:40 INFO Client: Application report for application_1589148979959_0010 (state: ACCEPTED)
20/05/11 05:40:41 INFO Client: Application report for application_1589148979959_0010 (state: ACCEPTED)
20/05/11 05:40:42 INFO Client: Application report for application_1589148979959_0010 (state: ACCEPTED)
20/05/11 05:40:43 INFO Client: Application report for application_1589148979959_0010 (state: ACCEPTED)
20/05/11 05:40:44 INFO Client: Application report for application_1589148979959_0010 (state: ACCEPTED)
20/05/11 05:40:45 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0010), /proxy/application_1589148979959_0010
20/05/11 05:40:45 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 05:40:45 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 05:40:45 INFO Client: Application report for application_1589148979959_0010 (state: RUNNING)
20/05/11 05:40:45 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.20.197
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589175637849
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0010/
	 user: hadoop
20/05/11 05:40:45 INFO YarnClientSchedulerBackend: Application application_1589148979959_0010 has started running.
20/05/11 05:40:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38889.
20/05/11 05:40:45 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:38889
20/05/11 05:40:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 05:40:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 38889, None)
20/05/11 05:40:46 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:38889 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 38889, None)
20/05/11 05:40:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 38889, None)
20/05/11 05:40:46 INFO BlockManager: external shuffle service port = 7337
20/05/11 05:40:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 38889, None)
20/05/11 05:40:46 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 05:40:47 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0010
20/05/11 05:40:47 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 05:40:47 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
TERMINATED: No more infectious nodes left to update
Finish simulation: 1
Begin simulation: 2
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-8052a168-e981-4b8d-b4fd-0f39fa48654b;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 937ms :: artifacts dl 31ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-8052a168-e981-4b8d-b4fd-0f39fa48654b
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/25ms)
20/05/11 06:19:04 INFO SparkContext: Running Spark version 2.4.4
20/05/11 06:19:04 INFO SparkContext: Submitted application: cluster_run
20/05/11 06:19:04 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 06:19:04 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 06:19:04 INFO SecurityManager: Changing view acls groups to: 
20/05/11 06:19:04 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 06:19:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 06:19:05 INFO Utils: Successfully started service 'sparkDriver' on port 35259.
20/05/11 06:19:05 INFO SparkEnv: Registering MapOutputTracker
20/05/11 06:19:05 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 06:19:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 06:19:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 06:19:06 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-5b29e1cd-46f7-4097-9b73-d3d8dd0e8226
20/05/11 06:19:06 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 06:19:06 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 06:19:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 06:19:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 06:19:07 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 06:19:09 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 06:19:10 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 06:19:10 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 06:19:10 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 06:19:10 INFO Client: Setting up container launch context for our AM
20/05/11 06:19:10 INFO Client: Setting up the launch environment for our AM container
20/05/11 06:19:10 INFO Client: Preparing resources for our AM container
20/05/11 06:19:10 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 06:19:17 INFO Client: Uploading resource file:/mnt/tmp/spark-adc495ac-303c-4f62-aeb7-3af40af9da76/__spark_libs__934070314886705950.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0011/__spark_libs__934070314886705950.zip
20/05/11 06:19:19 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0011/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 06:19:19 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0011/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 06:19:19 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0011/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 06:19:19 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0011/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 06:19:19 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0011/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 06:19:19 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0011/pyspark.zip
20/05/11 06:19:19 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0011/py4j-0.10.7-src.zip
20/05/11 06:19:20 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 06:19:20 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 06:19:20 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 06:19:20 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 06:19:20 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 06:19:20 INFO Client: Uploading resource file:/mnt/tmp/spark-adc495ac-303c-4f62-aeb7-3af40af9da76/__spark_conf__3507902631976182103.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0011/__spark_conf__.zip
20/05/11 06:19:20 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 06:19:20 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 06:19:20 INFO SecurityManager: Changing view acls groups to: 
20/05/11 06:19:20 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 06:19:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 06:19:24 INFO Client: Submitting application application_1589148979959_0011 to ResourceManager
20/05/11 06:19:24 INFO YarnClientImpl: Submitted application application_1589148979959_0011
20/05/11 06:19:25 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0011 and attemptId None
20/05/11 06:19:26 INFO Client: Application report for application_1589148979959_0011 (state: ACCEPTED)
20/05/11 06:19:26 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589177964931
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0011/
	 user: hadoop
20/05/11 06:19:27 INFO Client: Application report for application_1589148979959_0011 (state: ACCEPTED)
20/05/11 06:19:28 INFO Client: Application report for application_1589148979959_0011 (state: ACCEPTED)
20/05/11 06:19:29 INFO Client: Application report for application_1589148979959_0011 (state: ACCEPTED)
20/05/11 06:19:30 INFO Client: Application report for application_1589148979959_0011 (state: ACCEPTED)
20/05/11 06:19:31 INFO Client: Application report for application_1589148979959_0011 (state: ACCEPTED)
20/05/11 06:19:31 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0011), /proxy/application_1589148979959_0011
20/05/11 06:19:31 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 06:19:31 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 06:19:32 INFO Client: Application report for application_1589148979959_0011 (state: RUNNING)
20/05/11 06:19:32 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.21.217
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589177964931
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0011/
	 user: hadoop
20/05/11 06:19:32 INFO YarnClientSchedulerBackend: Application application_1589148979959_0011 has started running.
20/05/11 06:19:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32909.
20/05/11 06:19:32 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:32909
20/05/11 06:19:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 06:19:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 32909, None)
20/05/11 06:19:32 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:32909 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 32909, None)
20/05/11 06:19:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 32909, None)
20/05/11 06:19:32 INFO BlockManager: external shuffle service port = 7337
20/05/11 06:19:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 32909, None)
20/05/11 06:19:33 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 06:19:33 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0011
20/05/11 06:19:33 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 06:19:34 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
20/05/11 06:25:30 ERROR Utils: Uncaught exception in thread heartbeat-receiver-event-loop-thread
java.lang.NullPointerException
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:479)
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:451)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:593)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:186)
	at org.apache.spark.scheduler.TaskSchedulerImpl.executorHeartbeatReceived(TaskSchedulerImpl.scala:593)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2$$anonfun$run$2.apply$mcV$sp(HeartbeatReceiver.scala:128)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2.run(HeartbeatReceiver.scala:127)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/05/11 06:36:44 ERROR TransportClient: Failed to send RPC RPC 6538115177751382953 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:44 ERROR TransportClient: Failed to send RPC RPC 7050849093963583958 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:44 ERROR TransportClient: Failed to send RPC RPC 8891190700146134152 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:44 ERROR YarnScheduler: Lost executor 3 on ip-172-31-21-217.us-east-2.compute.internal: Slave lost
20/05/11 06:36:44 ERROR YarnScheduler: Lost executor 2 on ip-172-31-17-6.us-east-2.compute.internal: Slave lost
20/05/11 06:36:44 ERROR YarnScheduler: Lost executor 1 on ip-172-31-20-197.us-east-2.compute.internal: Slave lost
20/05/11 06:36:44 ERROR TransportClient: Failed to send RPC RPC 4678495890074787212 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:44 ERROR YarnScheduler: Lost executor 4 on ip-172-31-25-89.us-east-2.compute.internal: Slave lost
20/05/11 06:36:45 ERROR TransportClient: Failed to send RPC RPC 7060319350895782027 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:45 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(1,0,Map(),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7060319350895782027 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:46 ERROR TransportClient: Failed to send RPC RPC 8210496618604958634 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:46 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(1,0,Map(),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8210496618604958634 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:47 ERROR TransportClient: Failed to send RPC RPC 6477305461738872339 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:47 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(1,0,Map(),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 6477305461738872339 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:48 ERROR TransportClient: Failed to send RPC RPC 6751118373647732443 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:48 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(1,0,Map(),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 6751118373647732443 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:49 ERROR TransportClient: Failed to send RPC RPC 8000829716463504701 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:36:49 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(1,0,Map(),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8000829716463504701 to /172.31.21.217:41660: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 06:56:01 ERROR Utils: Uncaught exception in thread heartbeat-receiver-event-loop-thread
java.lang.NullPointerException
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:479)
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:451)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:593)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:186)
	at org.apache.spark.scheduler.TaskSchedulerImpl.executorHeartbeatReceived(TaskSchedulerImpl.scala:593)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2$$anonfun$run$2.apply$mcV$sp(HeartbeatReceiver.scala:128)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2.run(HeartbeatReceiver.scala:127)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/05/11 07:00:50 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /172.31.17.6:40414 is closed
20/05/11 07:00:50 ERROR YarnScheduler: Lost executor 7 on ip-172-31-25-89.us-east-2.compute.internal: Slave lost
20/05/11 07:00:51 ERROR TransportClient: Failed to send RPC RPC 5406607571629532360 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:51 ERROR YarnScheduler: Lost executor 6 on ip-172-31-20-197.us-east-2.compute.internal: Slave lost
20/05/11 07:00:51 ERROR TransportClient: Failed to send RPC RPC 8744033684779137143 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:51 ERROR YarnScheduler: Lost executor 5 on ip-172-31-17-6.us-east-2.compute.internal: Slave lost
20/05/11 07:00:51 ERROR TransportClient: Failed to send RPC RPC 6462171905165005508 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:51 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(5,1,Map(ip-172-31-20-197.us-east-2.compute.internal -> 1),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 6462171905165005508 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:52 ERROR TransportClient: Failed to send RPC RPC 7665574160417641829 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:52 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(5,1,Map(ip-172-31-20-197.us-east-2.compute.internal -> 1),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7665574160417641829 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:53 ERROR TransportClient: Failed to send RPC RPC 8876135029957929536 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:53 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(5,1,Map(ip-172-31-20-197.us-east-2.compute.internal -> 1),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8876135029957929536 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:54 ERROR TransportClient: Failed to send RPC RPC 4679547895610928795 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:54 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(5,1,Map(ip-172-31-20-197.us-east-2.compute.internal -> 1),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 4679547895610928795 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:55 ERROR TransportClient: Failed to send RPC RPC 7781580931613365496 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:55 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(5,1,Map(ip-172-31-20-197.us-east-2.compute.internal -> 1),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7781580931613365496 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:56 ERROR TransportClient: Failed to send RPC RPC 5500244780571839881 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:00:56 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(5,1,Map(ip-172-31-20-197.us-east-2.compute.internal -> 1),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 5500244780571839881 to /172.31.17.6:40414: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
TERMINATED: No more infectious nodes left to update
Finish simulation: 2
Begin simulation: 3
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-7044179a-1774-44eb-87ee-f4ef24904917;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 724ms :: artifacts dl 30ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-7044179a-1774-44eb-87ee-f4ef24904917
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/31ms)
20/05/11 07:21:29 INFO SparkContext: Running Spark version 2.4.4
20/05/11 07:21:29 INFO SparkContext: Submitted application: cluster_run
20/05/11 07:21:29 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 07:21:29 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 07:21:29 INFO SecurityManager: Changing view acls groups to: 
20/05/11 07:21:29 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 07:21:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 07:21:30 INFO Utils: Successfully started service 'sparkDriver' on port 40251.
20/05/11 07:21:30 INFO SparkEnv: Registering MapOutputTracker
20/05/11 07:21:30 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 07:21:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 07:21:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 07:21:30 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-f9bd5b2a-e998-4e51-937f-71037969c0e3
20/05/11 07:21:30 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 07:21:30 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 07:21:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 07:21:31 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 07:21:31 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 07:21:33 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 07:21:34 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 07:21:34 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 07:21:34 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 07:21:34 INFO Client: Setting up container launch context for our AM
20/05/11 07:21:34 INFO Client: Setting up the launch environment for our AM container
20/05/11 07:21:34 INFO Client: Preparing resources for our AM container
20/05/11 07:21:34 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 07:21:38 INFO Client: Uploading resource file:/mnt/tmp/spark-39e53a24-af44-492e-af0b-cc2e60f27683/__spark_libs__4999548156512306427.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0012/__spark_libs__4999548156512306427.zip
20/05/11 07:21:41 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0012/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 07:21:41 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0012/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 07:21:41 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0012/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 07:21:41 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0012/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 07:21:41 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0012/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 07:21:41 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0012/pyspark.zip
20/05/11 07:21:41 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0012/py4j-0.10.7-src.zip
20/05/11 07:21:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 07:21:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 07:21:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 07:21:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 07:21:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 07:21:41 INFO Client: Uploading resource file:/mnt/tmp/spark-39e53a24-af44-492e-af0b-cc2e60f27683/__spark_conf__7090454226943782409.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0012/__spark_conf__.zip
20/05/11 07:21:41 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 07:21:41 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 07:21:41 INFO SecurityManager: Changing view acls groups to: 
20/05/11 07:21:41 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 07:21:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 07:21:45 INFO Client: Submitting application application_1589148979959_0012 to ResourceManager
20/05/11 07:21:46 INFO YarnClientImpl: Submitted application application_1589148979959_0012
20/05/11 07:21:46 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0012 and attemptId None
20/05/11 07:21:47 INFO Client: Application report for application_1589148979959_0012 (state: ACCEPTED)
20/05/11 07:21:47 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589181706017
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0012/
	 user: hadoop
20/05/11 07:21:48 INFO Client: Application report for application_1589148979959_0012 (state: ACCEPTED)
20/05/11 07:21:49 INFO Client: Application report for application_1589148979959_0012 (state: ACCEPTED)
20/05/11 07:21:50 INFO Client: Application report for application_1589148979959_0012 (state: ACCEPTED)
20/05/11 07:21:51 INFO Client: Application report for application_1589148979959_0012 (state: ACCEPTED)
20/05/11 07:21:52 INFO Client: Application report for application_1589148979959_0012 (state: ACCEPTED)
20/05/11 07:21:53 INFO Client: Application report for application_1589148979959_0012 (state: RUNNING)
20/05/11 07:21:53 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.20.197
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589181706017
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0012/
	 user: hadoop
20/05/11 07:21:53 INFO YarnClientSchedulerBackend: Application application_1589148979959_0012 has started running.
20/05/11 07:21:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37557.
20/05/11 07:21:53 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:37557
20/05/11 07:21:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 07:21:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37557, None)
20/05/11 07:21:53 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:37557 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37557, None)
20/05/11 07:21:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37557, None)
20/05/11 07:21:53 INFO BlockManager: external shuffle service port = 7337
20/05/11 07:21:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37557, None)
20/05/11 07:21:53 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0012), /proxy/application_1589148979959_0012
20/05/11 07:21:53 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 07:21:54 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 07:21:54 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 07:21:55 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0012
20/05/11 07:21:55 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 07:21:55 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
20/05/11 07:23:39 ERROR AsyncEventQueue: Dropping event from queue eventLog. This likely means one of the listeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
20/05/11 07:28:45 ERROR YarnScheduler: Lost executor 1 on ip-172-31-25-89.us-east-2.compute.internal: Container marked as failed: container_1589148979959_0012_01_000002 on host: ip-172-31-25-89.us-east-2.compute.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.
20/05/11 07:28:49 ERROR TransportClient: Failed to send RPC RPC 6559297865328109976 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:49 ERROR TransportClient: Failed to send RPC RPC 5245365198307932401 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:49 ERROR YarnScheduler: Lost executor 2 on ip-172-31-20-197.us-east-2.compute.internal: Slave lost
20/05/11 07:28:49 ERROR YarnScheduler: Lost executor 3 on ip-172-31-21-94.us-east-2.compute.internal: Slave lost
20/05/11 07:28:50 ERROR TransportClient: Failed to send RPC RPC 7263336637488770638 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:50 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(2,1,Map(ip-172-31-25-89.us-east-2.compute.internal -> 1),Set(ip-172-31-21-217.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7263336637488770638 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:51 ERROR TransportClient: Failed to send RPC RPC 7173016452084255264 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:51 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(2,1,Map(ip-172-31-25-89.us-east-2.compute.internal -> 1),Set(ip-172-31-21-217.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7173016452084255264 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:52 ERROR TransportClient: Failed to send RPC RPC 6166704204367566416 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:52 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(2,1,Map(ip-172-31-25-89.us-east-2.compute.internal -> 1),Set(ip-172-31-21-217.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 6166704204367566416 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:53 ERROR TransportClient: Failed to send RPC RPC 7445615017865382829 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:53 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(2,1,Map(ip-172-31-25-89.us-east-2.compute.internal -> 1),Set(ip-172-31-21-217.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7445615017865382829 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:54 ERROR TransportClient: Failed to send RPC RPC 7279348592400608661 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:54 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(2,1,Map(ip-172-31-25-89.us-east-2.compute.internal -> 1),Set(ip-172-31-21-217.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7279348592400608661 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:55 ERROR TransportClient: Failed to send RPC RPC 9198921782465585529 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:55 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(2,1,Map(ip-172-31-25-89.us-east-2.compute.internal -> 1),Set(ip-172-31-21-217.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 9198921782465585529 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:56 ERROR TransportClient: Failed to send RPC RPC 7373778482214029473 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:56 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(2,1,Map(ip-172-31-25-89.us-east-2.compute.internal -> 1),Set(ip-172-31-21-217.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7373778482214029473 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:57 ERROR TransportClient: Failed to send RPC RPC 6422293168352583384 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:28:57 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(2,1,Map(ip-172-31-25-89.us-east-2.compute.internal -> 1),Set(ip-172-31-21-217.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 6422293168352583384 to /172.31.20.197:46918: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 07:29:15 ERROR YarnClientSchedulerBackend: YARN application has exited unexpectedly with state FAILED! Check the YARN application logs for more details.
20/05/11 07:29:15 ERROR YarnClientSchedulerBackend: Diagnostics message: Due to executor failures all available nodes are blacklisted
Traceback (most recent call last):
  File "/home/hadoop/network_update_GF_monte_carlo_cluster.py", line 418, in <module>
    nodes_counter, duration = simulate(g, args.p_is, args.p_id, args.p_ih, args.p_ir, args.p_hr, args.p_hd, args.t_latent, args.t_infectious, args.num_i_seeds, args.num_time_steps)
  File "/home/hadoop/network_update_GF_monte_carlo_cluster.py", line 345, in simulate
    new_E_nodes = S_flow(g, s_nodes, e_nodes, i_nodes, r_nodes, h_nodes, d_nodes, p_is, p_id, p_ih, p_ir, t_infectious)
  File "/home/hadoop/network_update_GF_monte_carlo_cluster.py", line 263, in S_flow
    neighbors = g.vertices.filter(col("id").isin([node])).select("neighbors").toPandas()["neighbors"][0]
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 2143, in toPandas
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 534, in collect
  File "/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
  File "/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o1497.collectToPython.
: org.apache.spark.SparkException: Job 35 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:972)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:970)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:970)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2286)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2193)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:121)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:335)
	at org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)
	at org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)
	at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:84)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:165)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)
	at org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)
	at sun.reflect.GeneratedMethodAccessor65.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

20/05/11 07:29:15 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:274)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:105)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
20/05/11 07:29:15 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:274)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:105)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
20/05/11 07:29:15 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.
org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:160)
	at org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:140)
	at org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:655)
	at org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:274)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:105)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Finish simulation: 3
Begin simulation: 4
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-29a64f53-d578-4fc8-94f4-b19af44c4add;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 924ms :: artifacts dl 31ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-29a64f53-d578-4fc8-94f4-b19af44c4add
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/39ms)
20/05/11 07:29:30 INFO SparkContext: Running Spark version 2.4.4
20/05/11 07:29:30 INFO SparkContext: Submitted application: cluster_run
20/05/11 07:29:31 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 07:29:31 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 07:29:31 INFO SecurityManager: Changing view acls groups to: 
20/05/11 07:29:31 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 07:29:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 07:29:32 INFO Utils: Successfully started service 'sparkDriver' on port 42403.
20/05/11 07:29:32 INFO SparkEnv: Registering MapOutputTracker
20/05/11 07:29:32 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 07:29:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 07:29:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 07:29:32 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-696894ef-c38e-425e-8f0f-bb882fb32577
20/05/11 07:29:32 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 07:29:32 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 07:29:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 07:29:33 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 07:29:33 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 07:29:35 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 07:29:36 INFO Client: Requesting a new application from cluster with 5 NodeManagers
20/05/11 07:29:36 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 07:29:36 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 07:29:36 INFO Client: Setting up container launch context for our AM
20/05/11 07:29:36 INFO Client: Setting up the launch environment for our AM container
20/05/11 07:29:36 INFO Client: Preparing resources for our AM container
20/05/11 07:29:36 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 07:29:41 INFO Client: Uploading resource file:/mnt/tmp/spark-29aa4e83-10a3-4a63-b498-27e8a55698b5/__spark_libs__8698734330091914888.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0013/__spark_libs__8698734330091914888.zip
20/05/11 07:29:43 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0013/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 07:29:43 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0013/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 07:29:43 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0013/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 07:29:43 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0013/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 07:29:44 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0013/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 07:29:44 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0013/pyspark.zip
20/05/11 07:29:45 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0013/py4j-0.10.7-src.zip
20/05/11 07:29:45 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 07:29:45 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 07:29:45 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 07:29:45 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 07:29:45 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 07:29:45 INFO Client: Uploading resource file:/mnt/tmp/spark-29aa4e83-10a3-4a63-b498-27e8a55698b5/__spark_conf__301289788839106213.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0013/__spark_conf__.zip
20/05/11 07:29:45 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 07:29:45 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 07:29:45 INFO SecurityManager: Changing view acls groups to: 
20/05/11 07:29:45 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 07:29:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 07:29:49 INFO Client: Submitting application application_1589148979959_0013 to ResourceManager
20/05/11 07:29:49 INFO YarnClientImpl: Submitted application application_1589148979959_0013
20/05/11 07:29:49 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0013 and attemptId None
20/05/11 07:29:50 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:29:50 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589182189329
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0013/
	 user: hadoop
20/05/11 07:29:51 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:29:52 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:29:53 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:29:54 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:29:55 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:29:56 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:29:57 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:29:58 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:29:59 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:00 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:01 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:02 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:03 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:04 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:05 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:06 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:07 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:08 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:09 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:10 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:11 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:12 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:13 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:14 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:15 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:16 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:17 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:18 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:19 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:20 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:21 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:22 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:23 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:24 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:25 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:26 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:27 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:28 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:29 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:30 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:31 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:32 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:33 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:34 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:35 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:36 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:37 INFO Client: Application report for application_1589148979959_0013 (state: ACCEPTED)
20/05/11 07:30:38 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0013), /proxy/application_1589148979959_0013
20/05/11 07:30:38 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 07:30:38 INFO Client: Application report for application_1589148979959_0013 (state: RUNNING)
20/05/11 07:30:38 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.21.94
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589182189329
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0013/
	 user: hadoop
20/05/11 07:30:38 INFO YarnClientSchedulerBackend: Application application_1589148979959_0013 has started running.
20/05/11 07:30:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37037.
20/05/11 07:30:38 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:37037
20/05/11 07:30:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 07:30:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37037, None)
20/05/11 07:30:38 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:37037 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37037, None)
20/05/11 07:30:38 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 07:30:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37037, None)
20/05/11 07:30:38 INFO BlockManager: external shuffle service port = 7337
20/05/11 07:30:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37037, None)
20/05/11 07:30:39 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 07:30:39 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0013
20/05/11 07:30:39 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 07:30:39 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
20/05/11 07:47:42 ERROR AsyncEventQueue: Dropping event from queue eventLog. This likely means one of the listeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
TERMINATED: No more infectious nodes left to update
Finish simulation: 4
Begin simulation: 5
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-33622903-d72b-4fba-84d0-c344d5d45207;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 868ms :: artifacts dl 17ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-33622903-d72b-4fba-84d0-c344d5d45207
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/35ms)
20/05/11 07:49:05 INFO SparkContext: Running Spark version 2.4.4
20/05/11 07:49:05 INFO SparkContext: Submitted application: cluster_run
20/05/11 07:49:05 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 07:49:05 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 07:49:05 INFO SecurityManager: Changing view acls groups to: 
20/05/11 07:49:05 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 07:49:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 07:49:07 INFO Utils: Successfully started service 'sparkDriver' on port 40399.
20/05/11 07:49:07 INFO SparkEnv: Registering MapOutputTracker
20/05/11 07:49:07 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 07:49:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 07:49:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 07:49:07 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-d0a1ccc7-abad-4b5b-b627-58cf09f8d037
20/05/11 07:49:07 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 07:49:07 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 07:49:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 07:49:08 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 07:49:09 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 07:49:11 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 07:49:12 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 07:49:12 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 07:49:12 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 07:49:12 INFO Client: Setting up container launch context for our AM
20/05/11 07:49:12 INFO Client: Setting up the launch environment for our AM container
20/05/11 07:49:12 INFO Client: Preparing resources for our AM container
20/05/11 07:49:12 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 07:49:18 INFO Client: Uploading resource file:/mnt/tmp/spark-f18ee9c2-d2d9-4e49-a370-2b98215120ea/__spark_libs__6930220501164286823.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0014/__spark_libs__6930220501164286823.zip
20/05/11 07:49:21 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0014/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 07:49:21 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0014/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 07:49:21 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0014/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 07:49:21 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0014/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 07:49:21 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0014/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 07:49:21 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0014/pyspark.zip
20/05/11 07:49:21 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0014/py4j-0.10.7-src.zip
20/05/11 07:49:21 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 07:49:21 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 07:49:21 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 07:49:21 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 07:49:21 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 07:49:22 INFO Client: Uploading resource file:/mnt/tmp/spark-f18ee9c2-d2d9-4e49-a370-2b98215120ea/__spark_conf__2983266631728090365.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0014/__spark_conf__.zip
20/05/11 07:49:22 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 07:49:22 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 07:49:22 INFO SecurityManager: Changing view acls groups to: 
20/05/11 07:49:22 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 07:49:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 07:49:26 INFO Client: Submitting application application_1589148979959_0014 to ResourceManager
20/05/11 07:49:27 INFO YarnClientImpl: Submitted application application_1589148979959_0014
20/05/11 07:49:27 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0014 and attemptId None
20/05/11 07:49:28 INFO Client: Application report for application_1589148979959_0014 (state: ACCEPTED)
20/05/11 07:49:28 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589183367042
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0014/
	 user: hadoop
20/05/11 07:49:29 INFO Client: Application report for application_1589148979959_0014 (state: ACCEPTED)
20/05/11 07:49:30 INFO Client: Application report for application_1589148979959_0014 (state: ACCEPTED)
20/05/11 07:49:31 INFO Client: Application report for application_1589148979959_0014 (state: ACCEPTED)
20/05/11 07:49:32 INFO Client: Application report for application_1589148979959_0014 (state: ACCEPTED)
20/05/11 07:49:33 INFO Client: Application report for application_1589148979959_0014 (state: ACCEPTED)
20/05/11 07:49:34 INFO Client: Application report for application_1589148979959_0014 (state: RUNNING)
20/05/11 07:49:34 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.21.94
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589183367042
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0014/
	 user: hadoop
20/05/11 07:49:34 INFO YarnClientSchedulerBackend: Application application_1589148979959_0014 has started running.
20/05/11 07:49:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45977.
20/05/11 07:49:34 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:45977
20/05/11 07:49:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 07:49:34 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0014), /proxy/application_1589148979959_0014
20/05/11 07:49:34 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 07:49:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 45977, None)
20/05/11 07:49:34 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:45977 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 45977, None)
20/05/11 07:49:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 45977, None)
20/05/11 07:49:34 INFO BlockManager: external shuffle service port = 7337
20/05/11 07:49:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 45977, None)
20/05/11 07:49:34 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 07:49:35 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 07:49:36 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0014
20/05/11 07:49:36 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 07:49:36 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
20/05/11 08:04:21 ERROR TransportClient: Failed to send RPC RPC 8394666102348388793 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:21 ERROR YarnScheduler: Lost executor 1 on ip-172-31-21-94.us-east-2.compute.internal: Slave lost
20/05/11 08:04:21 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /172.31.17.5:44178 is closed
20/05/11 08:04:21 ERROR TransportClient: Failed to send RPC RPC 6876150988938397058 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:21 ERROR YarnScheduler: Lost executor 2 on ip-172-31-17-5.us-east-2.compute.internal: Slave lost
20/05/11 08:04:22 ERROR TransportClient: Failed to send RPC RPC 5886984389813438876 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:22 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(8,184,Map(ip-172-31-17-5.us-east-2.compute.internal -> 184, ip-172-31-21-94.us-east-2.compute.internal -> 184),Set(ip-172-31-17-6.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 5886984389813438876 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:23 ERROR TransportClient: Failed to send RPC RPC 8543347968108251936 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:23 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(8,184,Map(ip-172-31-17-5.us-east-2.compute.internal -> 184, ip-172-31-21-94.us-east-2.compute.internal -> 184),Set(ip-172-31-17-6.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8543347968108251936 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:24 ERROR TransportClient: Failed to send RPC RPC 8975961600195723082 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:24 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(8,184,Map(ip-172-31-17-5.us-east-2.compute.internal -> 184, ip-172-31-21-94.us-east-2.compute.internal -> 184),Set(ip-172-31-17-6.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8975961600195723082 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:25 ERROR TransportClient: Failed to send RPC RPC 5236743746074976800 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:25 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(8,184,Map(ip-172-31-17-5.us-east-2.compute.internal -> 184, ip-172-31-21-94.us-east-2.compute.internal -> 184),Set(ip-172-31-17-6.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 5236743746074976800 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:26 ERROR TransportClient: Failed to send RPC RPC 8375803706158525962 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:26 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(8,184,Map(ip-172-31-17-5.us-east-2.compute.internal -> 184, ip-172-31-21-94.us-east-2.compute.internal -> 184),Set(ip-172-31-17-6.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8375803706158525962 to /172.31.21.94:35676: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:28 ERROR YarnClientSchedulerBackend: YARN application has exited unexpectedly with state FAILED! Check the YARN application logs for more details.
20/05/11 08:04:28 ERROR YarnClientSchedulerBackend: Diagnostics message: Due to executor failures all available nodes are blacklisted
20/05/11 08:04:28 ERROR TransportClient: Failed to send RPC RPC 8285986505997169016 to /172.31.17.5:44294: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:28 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(0,0,Map(),Set(ip-172-31-17-6.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8285986505997169016 to /172.31.17.5:44294: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 08:04:28 ERROR Utils: Uncaught exception in thread YARN application state monitor
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.requestTotalExecutors(CoarseGrainedSchedulerBackend.scala:599)
	at org.apache.spark.scheduler.cluster.YarnSchedulerBackend.stop(YarnSchedulerBackend.scala:103)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.stop(YarnClientSchedulerBackend.scala:164)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:653)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2194)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:121)
Caused by: java.io.IOException: Failed to send RPC RPC 8285986505997169016 to /172.31.17.5:44294: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
Traceback (most recent call last):
  File "/home/hadoop/network_update_GF_monte_carlo_cluster.py", line 418, in <module>
    nodes_counter, duration = simulate(g, args.p_is, args.p_id, args.p_ih, args.p_ir, args.p_hr, args.p_hd, args.t_latent, args.t_infectious, args.num_i_seeds, args.num_time_steps)
  File "/home/hadoop/network_update_GF_monte_carlo_cluster.py", line 345, in simulate
    new_E_nodes = S_flow(g, s_nodes, e_nodes, i_nodes, r_nodes, h_nodes, d_nodes, p_is, p_id, p_ih, p_ir, t_infectious)
  File "/home/hadoop/network_update_GF_monte_carlo_cluster.py", line 263, in S_flow
    neighbors = g.vertices.filter(col("id").isin([node])).select("neighbors").toPandas()["neighbors"][0]
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 2143, in toPandas
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 534, in collect
  File "/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
  File "/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o3771.collectToPython.
: org.apache.spark.SparkException: Job 85 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:972)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:970)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:970)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2286)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2193)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:121)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:335)
	at org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)
	at org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)
	at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:84)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:165)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)
	at org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)
	at sun.reflect.GeneratedMethodAccessor227.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

Finish simulation: 5
Begin simulation: 6
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-6545b0e2-1dd2-4697-b593-0ee66b56b346;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 665ms :: artifacts dl 13ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-6545b0e2-1dd2-4697-b593-0ee66b56b346
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/27ms)
20/05/11 08:04:41 INFO SparkContext: Running Spark version 2.4.4
20/05/11 08:04:41 INFO SparkContext: Submitted application: cluster_run
20/05/11 08:04:41 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 08:04:41 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 08:04:41 INFO SecurityManager: Changing view acls groups to: 
20/05/11 08:04:41 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 08:04:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 08:04:42 INFO Utils: Successfully started service 'sparkDriver' on port 35121.
20/05/11 08:04:42 INFO SparkEnv: Registering MapOutputTracker
20/05/11 08:04:43 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 08:04:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 08:04:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 08:04:43 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-9c533be4-2a0a-45a6-8be4-b1a724a0fd7d
20/05/11 08:04:43 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 08:04:43 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 08:04:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 08:04:44 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 08:04:44 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 08:04:46 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 08:04:46 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 08:04:46 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 08:04:46 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 08:04:46 INFO Client: Setting up container launch context for our AM
20/05/11 08:04:46 INFO Client: Setting up the launch environment for our AM container
20/05/11 08:04:47 INFO Client: Preparing resources for our AM container
20/05/11 08:04:47 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 08:04:52 INFO Client: Uploading resource file:/mnt/tmp/spark-a6dc0615-555c-4fb2-9e99-02e6380739d3/__spark_libs__2606112512324474896.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0015/__spark_libs__2606112512324474896.zip
20/05/11 08:04:54 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0015/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 08:04:54 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0015/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 08:04:54 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0015/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 08:04:54 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0015/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 08:04:54 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0015/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 08:04:54 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0015/pyspark.zip
20/05/11 08:04:54 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0015/py4j-0.10.7-src.zip
20/05/11 08:04:54 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 08:04:54 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 08:04:54 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 08:04:54 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 08:04:54 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 08:04:55 INFO Client: Uploading resource file:/mnt/tmp/spark-a6dc0615-555c-4fb2-9e99-02e6380739d3/__spark_conf__552187505098765480.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0015/__spark_conf__.zip
20/05/11 08:04:55 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 08:04:55 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 08:04:55 INFO SecurityManager: Changing view acls groups to: 
20/05/11 08:04:55 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 08:04:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 08:05:00 INFO Client: Submitting application application_1589148979959_0015 to ResourceManager
20/05/11 08:05:01 INFO YarnClientImpl: Submitted application application_1589148979959_0015
20/05/11 08:05:01 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0015 and attemptId None
20/05/11 08:05:02 INFO Client: Application report for application_1589148979959_0015 (state: ACCEPTED)
20/05/11 08:05:02 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589184300880
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0015/
	 user: hadoop
20/05/11 08:05:03 INFO Client: Application report for application_1589148979959_0015 (state: ACCEPTED)
20/05/11 08:05:04 INFO Client: Application report for application_1589148979959_0015 (state: ACCEPTED)
20/05/11 08:05:05 INFO Client: Application report for application_1589148979959_0015 (state: ACCEPTED)
20/05/11 08:05:06 INFO Client: Application report for application_1589148979959_0015 (state: ACCEPTED)
20/05/11 08:05:07 INFO Client: Application report for application_1589148979959_0015 (state: ACCEPTED)
20/05/11 08:05:08 INFO Client: Application report for application_1589148979959_0015 (state: ACCEPTED)
20/05/11 08:05:08 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0015), /proxy/application_1589148979959_0015
20/05/11 08:05:08 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 08:05:09 INFO Client: Application report for application_1589148979959_0015 (state: RUNNING)
20/05/11 08:05:09 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.17.5
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589184300880
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0015/
	 user: hadoop
20/05/11 08:05:09 INFO YarnClientSchedulerBackend: Application application_1589148979959_0015 has started running.
20/05/11 08:05:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38793.
20/05/11 08:05:09 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:38793
20/05/11 08:05:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 08:05:09 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 08:05:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 38793, None)
20/05/11 08:05:09 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:38793 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 38793, None)
20/05/11 08:05:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 38793, None)
20/05/11 08:05:09 INFO BlockManager: external shuffle service port = 7337
20/05/11 08:05:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 38793, None)
20/05/11 08:05:09 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 08:05:10 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0015
20/05/11 08:05:10 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 08:05:10 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
20/05/11 08:08:21 ERROR YarnScheduler: Lost executor 2 on ip-172-31-21-94.us-east-2.compute.internal: Container marked as failed: container_1589148979959_0015_01_000092 on host: ip-172-31-21-94.us-east-2.compute.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.
20/05/11 08:15:09 ERROR AsyncEventQueue: Dropping event from queue eventLog. This likely means one of the listeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
20/05/11 08:44:22 ERROR Utils: Uncaught exception in thread heartbeat-receiver-event-loop-thread
java.lang.NullPointerException
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:479)
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:451)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:593)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:186)
	at org.apache.spark.scheduler.TaskSchedulerImpl.executorHeartbeatReceived(TaskSchedulerImpl.scala:593)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2$$anonfun$run$2.apply$mcV$sp(HeartbeatReceiver.scala:128)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2.run(HeartbeatReceiver.scala:127)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/05/11 08:56:52 ERROR Utils: Uncaught exception in thread heartbeat-receiver-event-loop-thread
java.lang.NullPointerException
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:479)
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:451)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:593)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:186)
	at org.apache.spark.scheduler.TaskSchedulerImpl.executorHeartbeatReceived(TaskSchedulerImpl.scala:593)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2$$anonfun$run$2.apply$mcV$sp(HeartbeatReceiver.scala:128)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2.run(HeartbeatReceiver.scala:127)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/05/11 09:04:42 ERROR Utils: Uncaught exception in thread heartbeat-receiver-event-loop-thread
java.lang.NullPointerException
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:479)
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:451)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:593)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:186)
	at org.apache.spark.scheduler.TaskSchedulerImpl.executorHeartbeatReceived(TaskSchedulerImpl.scala:593)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2$$anonfun$run$2.apply$mcV$sp(HeartbeatReceiver.scala:128)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2.run(HeartbeatReceiver.scala:127)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/05/11 09:10:08 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /172.31.17.5:52772 is closed
20/05/11 09:10:08 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(115,368,Map(ip-172-31-17-5.us-east-2.compute.internal -> 368),Set(ip-172-31-25-89.us-east-2.compute.internal, ip-172-31-20-197.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:377)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
20/05/11 09:10:08 ERROR TransportClient: Failed to send RPC RPC 9137120344311432368 to /172.31.17.5:52772: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 09:10:08 ERROR YarnScheduler: Lost executor 1 on ip-172-31-17-5.us-east-2.compute.internal: Slave lost
20/05/11 09:10:45 ERROR YarnClientSchedulerBackend: YARN application has exited unexpectedly with state FAILED! Check the YARN application logs for more details.
20/05/11 09:10:45 ERROR YarnClientSchedulerBackend: Diagnostics message: Application application_1589148979959_0015 failed 2 times due to AM Container for appattempt_1589148979959_0015_000003 exited with  exitCode: -1000
Failing this attempt.Diagnostics: Could not obtain block: BP-1275493260-172.31.29.240-1589148938923:blk_1073742356_1534 file=/user/hadoop/.sparkStaging/application_1589148979959_0015/__spark_libs__2606112512324474896.zip
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1275493260-172.31.29.240-1589148938923:blk_1073742356_1534 file=/user/hadoop/.sparkStaging/application_1589148979959_0015/__spark_libs__2606112512324474896.zip
	at org.apache.hadoop.hdfs.DFSInputStream.refetchLocations(DFSInputStream.java:1053)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:1036)
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:1015)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:647)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:926)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:982)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:90)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:64)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:125)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:369)
	at org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:267)
	at org.apache.hadoop.yarn.util.FSDownload.access$000(FSDownload.java:63)
	at org.apache.hadoop.yarn.util.FSDownload$2.run(FSDownload.java:361)
	at org.apache.hadoop.yarn.util.FSDownload$2.run(FSDownload.java:359)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:359)
	at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:62)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

For more detailed output, check the application tracking page: http://ip-172-31-29-240.us-east-2.compute.internal:8088/cluster/app/application_1589148979959_0015 Then click on links to logs of each attempt.
. Failing the application.
20/05/11 09:10:45 ERROR TransportClient: Failed to send RPC RPC 6277524915258524109 to /172.31.17.5:52772: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 09:10:45 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(0,0,Map(),Set(ip-172-31-25-89.us-east-2.compute.internal, ip-172-31-20-197.us-east-2.compute.internal)) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 6277524915258524109 to /172.31.17.5:52772: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 09:10:45 ERROR Utils: Uncaught exception in thread YARN application state monitor
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.requestTotalExecutors(CoarseGrainedSchedulerBackend.scala:599)
	at org.apache.spark.scheduler.cluster.YarnSchedulerBackend.stop(YarnSchedulerBackend.scala:103)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.stop(YarnClientSchedulerBackend.scala:164)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:653)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2194)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:121)
Caused by: java.io.IOException: Failed to send RPC RPC 6277524915258524109 to /172.31.17.5:52772: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
Traceback (most recent call last):
  File "/home/hadoop/network_update_GF_monte_carlo_cluster.py", line 418, in <module>
    nodes_counter, duration = simulate(g, args.p_is, args.p_id, args.p_ih, args.p_ir, args.p_hr, args.p_hd, args.t_latent, args.t_infectious, args.num_i_seeds, args.num_time_steps)
  File "/home/hadoop/network_update_GF_monte_carlo_cluster.py", line 344, in simulate
    new_I_nodes = E_flow(g, e_nodes, i_nodes, t_latent)
  File "/home/hadoop/network_update_GF_monte_carlo_cluster.py", line 242, in E_flow
    e_days = g.vertices.filter(col("id").isin([node])).select("e_days").toPandas()["e_days"][0]
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 2143, in toPandas
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 534, in collect
  File "/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
  File "/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o16120.collectToPython.
: org.apache.spark.SparkException: Job 382 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:972)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:970)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:970)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2286)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2193)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:121)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:335)
	at org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)
	at org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)
	at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:84)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:165)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:74)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)
	at org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)
	at sun.reflect.GeneratedMethodAccessor65.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

Finish simulation: 6
Begin simulation: 7
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-47cfb4dd-4361-468a-83ff-fa9da47d5e30;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 698ms :: artifacts dl 25ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-47cfb4dd-4361-468a-83ff-fa9da47d5e30
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/41ms)
20/05/11 09:10:58 INFO SparkContext: Running Spark version 2.4.4
20/05/11 09:10:58 INFO SparkContext: Submitted application: cluster_run
20/05/11 09:10:59 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:10:59 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:10:59 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:10:59 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:10:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:11:00 INFO Utils: Successfully started service 'sparkDriver' on port 38661.
20/05/11 09:11:00 INFO SparkEnv: Registering MapOutputTracker
20/05/11 09:11:00 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 09:11:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 09:11:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 09:11:00 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-ab20e13e-92da-4118-bac3-74782afb3ebd
20/05/11 09:11:00 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 09:11:00 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 09:11:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 09:11:01 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 09:11:01 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:11:02 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 09:11:03 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 09:11:03 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 09:11:03 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 09:11:03 INFO Client: Setting up container launch context for our AM
20/05/11 09:11:03 INFO Client: Setting up the launch environment for our AM container
20/05/11 09:11:03 INFO Client: Preparing resources for our AM container
20/05/11 09:11:03 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 09:11:07 INFO Client: Uploading resource file:/mnt/tmp/spark-6e862cad-c33d-4a11-a1b4-c866a6f48a00/__spark_libs__5615359929304419064.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0016/__spark_libs__5615359929304419064.zip
20/05/11 09:11:09 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0016/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 09:11:09 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0016/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 09:11:09 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0016/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 09:11:09 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0016/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 09:11:09 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0016/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 09:11:09 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0016/pyspark.zip
20/05/11 09:11:09 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0016/py4j-0.10.7-src.zip
20/05/11 09:11:09 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 09:11:09 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:11:09 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:11:09 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 09:11:09 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 09:11:09 INFO Client: Uploading resource file:/mnt/tmp/spark-6e862cad-c33d-4a11-a1b4-c866a6f48a00/__spark_conf__2800530550453380660.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0016/__spark_conf__.zip
20/05/11 09:11:09 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:11:09 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:11:09 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:11:09 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:11:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:11:11 INFO Client: Submitting application application_1589148979959_0016 to ResourceManager
20/05/11 09:11:11 INFO YarnClientImpl: Submitted application application_1589148979959_0016
20/05/11 09:11:11 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0016 and attemptId None
20/05/11 09:11:12 INFO Client: Application report for application_1589148979959_0016 (state: ACCEPTED)
20/05/11 09:11:12 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589188271588
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0016/
	 user: hadoop
20/05/11 09:11:13 INFO Client: Application report for application_1589148979959_0016 (state: ACCEPTED)
20/05/11 09:11:14 INFO Client: Application report for application_1589148979959_0016 (state: ACCEPTED)
20/05/11 09:11:15 INFO Client: Application report for application_1589148979959_0016 (state: ACCEPTED)
20/05/11 09:11:16 INFO Client: Application report for application_1589148979959_0016 (state: ACCEPTED)
20/05/11 09:11:17 INFO Client: Application report for application_1589148979959_0016 (state: ACCEPTED)
20/05/11 09:11:18 INFO Client: Application report for application_1589148979959_0016 (state: RUNNING)
20/05/11 09:11:18 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.23.11
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589188271588
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0016/
	 user: hadoop
20/05/11 09:11:18 INFO YarnClientSchedulerBackend: Application application_1589148979959_0016 has started running.
20/05/11 09:11:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37923.
20/05/11 09:11:18 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:37923
20/05/11 09:11:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 09:11:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37923, None)
20/05/11 09:11:18 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:37923 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37923, None)
20/05/11 09:11:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37923, None)
20/05/11 09:11:18 INFO BlockManager: external shuffle service port = 7337
20/05/11 09:11:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37923, None)
20/05/11 09:11:19 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0016), /proxy/application_1589148979959_0016
20/05/11 09:11:19 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill, /metrics/json.
20/05/11 09:11:19 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0016
20/05/11 09:11:19 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:11:19 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
20/05/11 09:11:19 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 09:11:19 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
TERMINATED: No more infectious nodes left to update
Finish simulation: 7
Begin simulation: 8
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-12d516e8-2cbb-4737-b9f8-b03edfa3fb7a;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 1044ms :: artifacts dl 20ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-12d516e8-2cbb-4737-b9f8-b03edfa3fb7a
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/39ms)
20/05/11 09:24:42 INFO SparkContext: Running Spark version 2.4.4
20/05/11 09:24:42 INFO SparkContext: Submitted application: cluster_run
20/05/11 09:24:43 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:24:43 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:24:43 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:24:43 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:24:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:24:44 INFO Utils: Successfully started service 'sparkDriver' on port 39615.
20/05/11 09:24:44 INFO SparkEnv: Registering MapOutputTracker
20/05/11 09:24:44 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 09:24:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 09:24:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 09:24:44 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-406e346d-47ed-40ff-a607-9102bfba3170
20/05/11 09:24:44 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 09:24:45 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 09:24:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 09:24:46 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 09:24:46 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:24:49 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 09:24:50 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 09:24:50 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 09:24:50 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 09:24:50 INFO Client: Setting up container launch context for our AM
20/05/11 09:24:50 INFO Client: Setting up the launch environment for our AM container
20/05/11 09:24:50 INFO Client: Preparing resources for our AM container
20/05/11 09:24:50 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 09:25:00 INFO Client: Uploading resource file:/mnt/tmp/spark-c5cf21d5-4c8f-4d65-8766-5370610e935e/__spark_libs__4977526161543806656.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0017/__spark_libs__4977526161543806656.zip
20/05/11 09:25:03 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0017/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 09:25:03 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0017/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 09:25:03 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0017/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 09:25:03 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0017/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 09:25:03 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0017/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 09:25:03 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0017/pyspark.zip
20/05/11 09:25:03 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0017/py4j-0.10.7-src.zip
20/05/11 09:25:03 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 09:25:03 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:25:04 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:25:04 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 09:25:04 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 09:25:04 INFO Client: Uploading resource file:/mnt/tmp/spark-c5cf21d5-4c8f-4d65-8766-5370610e935e/__spark_conf__1071396246291861743.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0017/__spark_conf__.zip
20/05/11 09:25:04 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:25:04 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:25:04 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:25:04 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:25:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:25:10 INFO Client: Submitting application application_1589148979959_0017 to ResourceManager
20/05/11 09:25:10 INFO YarnClientImpl: Submitted application application_1589148979959_0017
20/05/11 09:25:10 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0017 and attemptId None
20/05/11 09:25:11 INFO Client: Application report for application_1589148979959_0017 (state: ACCEPTED)
20/05/11 09:25:11 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589189110248
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0017/
	 user: hadoop
20/05/11 09:25:12 INFO Client: Application report for application_1589148979959_0017 (state: ACCEPTED)
20/05/11 09:25:13 INFO Client: Application report for application_1589148979959_0017 (state: ACCEPTED)
20/05/11 09:25:14 INFO Client: Application report for application_1589148979959_0017 (state: ACCEPTED)
20/05/11 09:25:15 INFO Client: Application report for application_1589148979959_0017 (state: ACCEPTED)
20/05/11 09:25:16 INFO Client: Application report for application_1589148979959_0017 (state: ACCEPTED)
20/05/11 09:25:17 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0017), /proxy/application_1589148979959_0017
20/05/11 09:25:17 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 09:25:17 INFO Client: Application report for application_1589148979959_0017 (state: RUNNING)
20/05/11 09:25:17 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.23.11
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589189110248
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0017/
	 user: hadoop
20/05/11 09:25:17 INFO YarnClientSchedulerBackend: Application application_1589148979959_0017 has started running.
20/05/11 09:25:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42147.
20/05/11 09:25:17 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:42147
20/05/11 09:25:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 09:25:17 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 09:25:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 42147, None)
20/05/11 09:25:17 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:42147 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 42147, None)
20/05/11 09:25:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 42147, None)
20/05/11 09:25:17 INFO BlockManager: external shuffle service port = 7337
20/05/11 09:25:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 42147, None)
20/05/11 09:25:18 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 09:25:19 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0017
20/05/11 09:25:19 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:25:19 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
TERMINATED: No more infectious nodes left to update
Finish simulation: 8
Begin simulation: 9
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-1b892a9e-b3d0-4f74-bf49-6e7725cc6766;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 686ms :: artifacts dl 10ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-1b892a9e-b3d0-4f74-bf49-6e7725cc6766
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/23ms)
20/05/11 09:32:03 INFO SparkContext: Running Spark version 2.4.4
20/05/11 09:32:03 INFO SparkContext: Submitted application: cluster_run
20/05/11 09:32:03 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:32:03 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:32:03 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:32:03 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:32:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:32:04 INFO Utils: Successfully started service 'sparkDriver' on port 36575.
20/05/11 09:32:04 INFO SparkEnv: Registering MapOutputTracker
20/05/11 09:32:04 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 09:32:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 09:32:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 09:32:04 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-61ae5dfe-a2b2-4659-bdec-5866bec140ee
20/05/11 09:32:04 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 09:32:04 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 09:32:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 09:32:05 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 09:32:05 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:32:07 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 09:32:07 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 09:32:07 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 09:32:07 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 09:32:07 INFO Client: Setting up container launch context for our AM
20/05/11 09:32:07 INFO Client: Setting up the launch environment for our AM container
20/05/11 09:32:07 INFO Client: Preparing resources for our AM container
20/05/11 09:32:07 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 09:32:11 INFO Client: Uploading resource file:/mnt/tmp/spark-de63b63b-8e6d-4f35-83e6-7b1a022d4aa9/__spark_libs__9049470671451483310.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0018/__spark_libs__9049470671451483310.zip
20/05/11 09:32:13 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0018/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 09:32:13 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0018/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 09:32:13 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0018/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 09:32:13 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0018/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 09:32:13 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0018/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 09:32:13 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0018/pyspark.zip
20/05/11 09:32:13 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0018/py4j-0.10.7-src.zip
20/05/11 09:32:13 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 09:32:13 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:32:13 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:32:13 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 09:32:13 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 09:32:14 INFO Client: Uploading resource file:/mnt/tmp/spark-de63b63b-8e6d-4f35-83e6-7b1a022d4aa9/__spark_conf__7424837946403919263.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0018/__spark_conf__.zip
20/05/11 09:32:14 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:32:14 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:32:14 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:32:14 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:32:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:32:17 INFO Client: Submitting application application_1589148979959_0018 to ResourceManager
20/05/11 09:32:17 INFO YarnClientImpl: Submitted application application_1589148979959_0018
20/05/11 09:32:17 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0018 and attemptId None
20/05/11 09:32:18 INFO Client: Application report for application_1589148979959_0018 (state: ACCEPTED)
20/05/11 09:32:18 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589189537127
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0018/
	 user: hadoop
20/05/11 09:32:19 INFO Client: Application report for application_1589148979959_0018 (state: ACCEPTED)
20/05/11 09:32:20 INFO Client: Application report for application_1589148979959_0018 (state: ACCEPTED)
20/05/11 09:32:21 INFO Client: Application report for application_1589148979959_0018 (state: ACCEPTED)
20/05/11 09:32:22 INFO Client: Application report for application_1589148979959_0018 (state: ACCEPTED)
20/05/11 09:32:23 INFO Client: Application report for application_1589148979959_0018 (state: ACCEPTED)
20/05/11 09:32:24 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0018), /proxy/application_1589148979959_0018
20/05/11 09:32:24 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 09:32:24 INFO Client: Application report for application_1589148979959_0018 (state: RUNNING)
20/05/11 09:32:24 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.23.11
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589189537127
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0018/
	 user: hadoop
20/05/11 09:32:24 INFO YarnClientSchedulerBackend: Application application_1589148979959_0018 has started running.
20/05/11 09:32:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33441.
20/05/11 09:32:24 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:33441
20/05/11 09:32:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 09:32:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 33441, None)
20/05/11 09:32:24 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:33441 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 33441, None)
20/05/11 09:32:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 33441, None)
20/05/11 09:32:24 INFO BlockManager: external shuffle service port = 7337
20/05/11 09:32:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 33441, None)
20/05/11 09:32:24 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 09:32:24 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 09:32:25 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0018
20/05/11 09:32:25 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:32:25 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
20/05/11 09:33:40 ERROR Utils: Uncaught exception in thread heartbeat-receiver-event-loop-thread
java.lang.NullPointerException
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:479)
	at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:451)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11$$anonfun$12.apply(TaskSchedulerImpl.scala:594)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:594)
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11.apply(TaskSchedulerImpl.scala:593)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:186)
	at org.apache.spark.scheduler.TaskSchedulerImpl.executorHeartbeatReceived(TaskSchedulerImpl.scala:593)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2$$anonfun$run$2.apply$mcV$sp(HeartbeatReceiver.scala:128)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2.run(HeartbeatReceiver.scala:127)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
TERMINATED: No more infectious nodes left to update
Finish simulation: 9
Begin simulation: 10
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-cfcc2d90-a7dd-41e8-bbef-454e3e2fe675;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 724ms :: artifacts dl 20ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-cfcc2d90-a7dd-41e8-bbef-454e3e2fe675
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/33ms)
20/05/11 09:40:17 INFO SparkContext: Running Spark version 2.4.4
20/05/11 09:40:17 INFO SparkContext: Submitted application: cluster_run
20/05/11 09:40:18 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:40:18 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:40:18 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:40:18 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:40:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:40:18 INFO Utils: Successfully started service 'sparkDriver' on port 37811.
20/05/11 09:40:19 INFO SparkEnv: Registering MapOutputTracker
20/05/11 09:40:19 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 09:40:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 09:40:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 09:40:19 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-eafd9f40-63c0-4a86-bae6-80ec25e6cf45
20/05/11 09:40:19 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 09:40:19 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 09:40:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 09:40:19 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 09:40:20 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:40:21 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 09:40:22 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 09:40:22 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 09:40:22 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 09:40:22 INFO Client: Setting up container launch context for our AM
20/05/11 09:40:22 INFO Client: Setting up the launch environment for our AM container
20/05/11 09:40:22 INFO Client: Preparing resources for our AM container
20/05/11 09:40:22 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 09:40:27 INFO Client: Uploading resource file:/mnt/tmp/spark-fa4dc79b-e18a-4ed3-bfa7-8ddcfb746c5d/__spark_libs__6981694124488970043.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0019/__spark_libs__6981694124488970043.zip
20/05/11 09:40:29 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0019/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 09:40:29 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0019/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 09:40:30 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0019/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 09:40:30 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0019/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 09:40:30 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0019/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 09:40:30 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0019/pyspark.zip
20/05/11 09:40:30 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0019/py4j-0.10.7-src.zip
20/05/11 09:40:30 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 09:40:30 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:40:30 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:40:30 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 09:40:30 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 09:40:31 INFO Client: Uploading resource file:/mnt/tmp/spark-fa4dc79b-e18a-4ed3-bfa7-8ddcfb746c5d/__spark_conf__4892394131511289299.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0019/__spark_conf__.zip
20/05/11 09:40:31 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:40:31 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:40:31 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:40:31 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:40:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:40:34 INFO Client: Submitting application application_1589148979959_0019 to ResourceManager
20/05/11 09:40:34 INFO YarnClientImpl: Submitted application application_1589148979959_0019
20/05/11 09:40:34 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0019 and attemptId None
20/05/11 09:40:35 INFO Client: Application report for application_1589148979959_0019 (state: ACCEPTED)
20/05/11 09:40:35 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589190034087
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0019/
	 user: hadoop
20/05/11 09:40:36 INFO Client: Application report for application_1589148979959_0019 (state: ACCEPTED)
20/05/11 09:40:37 INFO Client: Application report for application_1589148979959_0019 (state: ACCEPTED)
20/05/11 09:40:38 INFO Client: Application report for application_1589148979959_0019 (state: ACCEPTED)
20/05/11 09:40:39 INFO Client: Application report for application_1589148979959_0019 (state: ACCEPTED)
20/05/11 09:40:40 INFO Client: Application report for application_1589148979959_0019 (state: ACCEPTED)
20/05/11 09:40:40 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0019), /proxy/application_1589148979959_0019
20/05/11 09:40:40 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 09:40:41 INFO Client: Application report for application_1589148979959_0019 (state: RUNNING)
20/05/11 09:40:41 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.23.11
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589190034087
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0019/
	 user: hadoop
20/05/11 09:40:41 INFO YarnClientSchedulerBackend: Application application_1589148979959_0019 has started running.
20/05/11 09:40:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42093.
20/05/11 09:40:41 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 09:40:41 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:42093
20/05/11 09:40:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 09:40:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 42093, None)
20/05/11 09:40:41 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:42093 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 42093, None)
20/05/11 09:40:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 42093, None)
20/05/11 09:40:41 INFO BlockManager: external shuffle service port = 7337
20/05/11 09:40:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 42093, None)
20/05/11 09:40:41 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 09:40:42 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0019
20/05/11 09:40:42 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:40:42 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
TERMINATED: No more infectious nodes left to update
Finish simulation: 10
Begin simulation: 11
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-de17211e-7782-4e5f-9c2e-3ac5037f73d3;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 630ms :: artifacts dl 29ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-de17211e-7782-4e5f-9c2e-3ac5037f73d3
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/36ms)
20/05/11 09:46:12 INFO SparkContext: Running Spark version 2.4.4
20/05/11 09:46:12 INFO SparkContext: Submitted application: cluster_run
20/05/11 09:46:12 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:46:12 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:46:12 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:46:12 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:46:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:46:13 INFO Utils: Successfully started service 'sparkDriver' on port 37869.
20/05/11 09:46:13 INFO SparkEnv: Registering MapOutputTracker
20/05/11 09:46:13 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 09:46:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 09:46:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 09:46:13 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-c40cb904-e38a-4de3-b960-5160aec2aaef
20/05/11 09:46:13 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 09:46:13 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 09:46:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 09:46:14 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 09:46:15 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:46:16 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 09:46:16 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 09:46:16 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 09:46:16 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 09:46:16 INFO Client: Setting up container launch context for our AM
20/05/11 09:46:16 INFO Client: Setting up the launch environment for our AM container
20/05/11 09:46:16 INFO Client: Preparing resources for our AM container
20/05/11 09:46:16 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 09:46:20 INFO Client: Uploading resource file:/mnt/tmp/spark-38814c1a-49f2-4227-b84e-008c6bd4a928/__spark_libs__7484266918528221929.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0020/__spark_libs__7484266918528221929.zip
20/05/11 09:46:22 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0020/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 09:46:22 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0020/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 09:46:22 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0020/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 09:46:22 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0020/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 09:46:22 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0020/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 09:46:22 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0020/pyspark.zip
20/05/11 09:46:22 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0020/py4j-0.10.7-src.zip
20/05/11 09:46:22 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 09:46:22 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:46:22 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:46:22 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 09:46:22 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 09:46:23 INFO Client: Uploading resource file:/mnt/tmp/spark-38814c1a-49f2-4227-b84e-008c6bd4a928/__spark_conf__6124589752744300309.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0020/__spark_conf__.zip
20/05/11 09:46:23 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:46:23 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:46:23 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:46:23 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:46:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:46:26 INFO Client: Submitting application application_1589148979959_0020 to ResourceManager
20/05/11 09:46:26 INFO YarnClientImpl: Submitted application application_1589148979959_0020
20/05/11 09:46:26 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0020 and attemptId None
20/05/11 09:46:27 INFO Client: Application report for application_1589148979959_0020 (state: ACCEPTED)
20/05/11 09:46:27 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589190386081
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0020/
	 user: hadoop
20/05/11 09:46:28 INFO Client: Application report for application_1589148979959_0020 (state: ACCEPTED)
20/05/11 09:46:29 INFO Client: Application report for application_1589148979959_0020 (state: ACCEPTED)
20/05/11 09:46:30 INFO Client: Application report for application_1589148979959_0020 (state: ACCEPTED)
20/05/11 09:46:31 INFO Client: Application report for application_1589148979959_0020 (state: ACCEPTED)
20/05/11 09:46:32 INFO Client: Application report for application_1589148979959_0020 (state: ACCEPTED)
20/05/11 09:46:33 INFO Client: Application report for application_1589148979959_0020 (state: RUNNING)
20/05/11 09:46:33 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.22.50
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589190386081
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0020/
	 user: hadoop
20/05/11 09:46:33 INFO YarnClientSchedulerBackend: Application application_1589148979959_0020 has started running.
20/05/11 09:46:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37983.
20/05/11 09:46:33 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:37983
20/05/11 09:46:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 09:46:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37983, None)
20/05/11 09:46:33 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:37983 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37983, None)
20/05/11 09:46:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37983, None)
20/05/11 09:46:33 INFO BlockManager: external shuffle service port = 7337
20/05/11 09:46:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 37983, None)
20/05/11 09:46:33 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0020), /proxy/application_1589148979959_0020
20/05/11 09:46:33 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 09:46:33 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 09:46:34 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 09:46:34 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0020
20/05/11 09:46:34 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:46:34 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
20/05/11 09:56:25 ERROR AsyncEventQueue: Dropping event from queue eventLog. This likely means one of the listeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
TERMINATED: No more infectious nodes left to update
Finish simulation: 11
Begin simulation: 12
Ivy Default Cache set to: /home/hadoop/.ivy2/cache
The jars for the packages stored in: /home/hadoop/.ivy2/jars
:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-020a003a-6414-4f2f-8e3a-7631c050709e;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-list
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 548ms :: artifacts dl 11ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-list in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-020a003a-6414-4f2f-8e3a-7631c050709e
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/32ms)
20/05/11 09:58:53 INFO SparkContext: Running Spark version 2.4.4
20/05/11 09:58:53 INFO SparkContext: Submitted application: cluster_run
20/05/11 09:58:53 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:58:53 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:58:53 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:58:53 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:58:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:58:54 INFO Utils: Successfully started service 'sparkDriver' on port 40305.
20/05/11 09:58:55 INFO SparkEnv: Registering MapOutputTracker
20/05/11 09:58:55 INFO SparkEnv: Registering BlockManagerMaster
20/05/11 09:58:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/05/11 09:58:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/05/11 09:58:55 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-44478850-e842-454a-b5e6-897677c508fe
20/05/11 09:58:55 INFO MemoryStore: MemoryStore started with capacity 1038.8 MB
20/05/11 09:58:55 INFO SparkEnv: Registering OutputCommitCoordinator
20/05/11 09:58:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/05/11 09:58:56 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-29-240.us-east-2.compute.internal:4040
20/05/11 09:58:56 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:58:57 INFO RMProxy: Connecting to ResourceManager at ip-172-31-29-240.us-east-2.compute.internal/172.31.29.240:8032
20/05/11 09:58:58 INFO Client: Requesting a new application from cluster with 4 NodeManagers
20/05/11 09:58:58 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
20/05/11 09:58:58 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
20/05/11 09:58:58 INFO Client: Setting up container launch context for our AM
20/05/11 09:58:58 INFO Client: Setting up the launch environment for our AM container
20/05/11 09:58:58 INFO Client: Preparing resources for our AM container
20/05/11 09:58:58 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/05/11 09:59:01 INFO Client: Uploading resource file:/mnt/tmp/spark-1f98933a-1fbf-400b-98a4-3a1a2e4ebf82/__spark_libs__1011575455052442141.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0021/__spark_libs__1011575455052442141.zip
20/05/11 09:59:06 INFO DataStreamer: Exception in createBlockOutputStream
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DataStreamer.createSocketForPipeline(DataStreamer.java:259)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1692)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1648)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:704)
20/05/11 09:59:06 WARN DataStreamer: Abandoning BP-1275493260-172.31.29.240-1589148938923:blk_1073742476_1656
20/05/11 09:59:06 WARN DataStreamer: Excluding datanode DatanodeInfoWithStorage[172.31.17.5:50010,DS-f6197222-e251-4851-84e9-fb14126c9464,DISK]
20/05/11 09:59:07 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0021/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
20/05/11 09:59:10 INFO DataStreamer: Exception in createBlockOutputStream
java.io.IOException: Got error, status=ERROR, status message , ack with firstBadLink as 172.31.17.5:50010
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:121)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1744)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1648)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:704)
20/05/11 09:59:10 WARN DataStreamer: Abandoning BP-1275493260-172.31.29.240-1589148938923:blk_1073742478_1658
20/05/11 09:59:10 WARN DataStreamer: Excluding datanode DatanodeInfoWithStorage[172.31.17.5:50010,DS-f6197222-e251-4851-84e9-fb14126c9464,DISK]
20/05/11 09:59:10 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0021/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar
20/05/11 09:59:10 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0021/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar
20/05/11 09:59:10 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0021/org.scala-lang_scala-reflect-2.11.0.jar
20/05/11 09:59:10 INFO Client: Uploading resource file:/home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0021/org.slf4j_slf4j-api-1.7.7.jar
20/05/11 09:59:10 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0021/pyspark.zip
20/05/11 09:59:10 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0021/py4j-0.10.7-src.zip
20/05/11 09:59:10 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar added multiple times to distributed cache.
20/05/11 09:59:10 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:59:10 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.
20/05/11 09:59:10 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.
20/05/11 09:59:10 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.
20/05/11 09:59:10 INFO Client: Uploading resource file:/mnt/tmp/spark-1f98933a-1fbf-400b-98a4-3a1a2e4ebf82/__spark_conf__5263974499305462972.zip -> hdfs://ip-172-31-29-240.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1589148979959_0021/__spark_conf__.zip
20/05/11 09:59:13 INFO DataStreamer: Exception in createBlockOutputStream
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DataStreamer.createSocketForPipeline(DataStreamer.java:259)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1692)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1648)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:704)
20/05/11 09:59:13 WARN DataStreamer: Abandoning BP-1275493260-172.31.29.240-1589148938923:blk_1073742486_1666
20/05/11 09:59:13 WARN DataStreamer: Excluding datanode DatanodeInfoWithStorage[172.31.17.5:50010,DS-f6197222-e251-4851-84e9-fb14126c9464,DISK]
20/05/11 09:59:14 INFO SecurityManager: Changing view acls to: hadoop
20/05/11 09:59:14 INFO SecurityManager: Changing modify acls to: hadoop
20/05/11 09:59:14 INFO SecurityManager: Changing view acls groups to: 
20/05/11 09:59:14 INFO SecurityManager: Changing modify acls groups to: 
20/05/11 09:59:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/05/11 09:59:17 INFO Client: Submitting application application_1589148979959_0021 to ResourceManager
20/05/11 09:59:17 INFO YarnClientImpl: Submitted application application_1589148979959_0021
20/05/11 09:59:17 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1589148979959_0021 and attemptId None
20/05/11 09:59:18 INFO Client: Application report for application_1589148979959_0021 (state: ACCEPTED)
20/05/11 09:59:18 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589191157116
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0021/
	 user: hadoop
20/05/11 09:59:19 INFO Client: Application report for application_1589148979959_0021 (state: ACCEPTED)
20/05/11 09:59:20 INFO Client: Application report for application_1589148979959_0021 (state: ACCEPTED)
20/05/11 09:59:21 INFO Client: Application report for application_1589148979959_0021 (state: ACCEPTED)
20/05/11 09:59:22 INFO Client: Application report for application_1589148979959_0021 (state: ACCEPTED)
20/05/11 09:59:23 INFO Client: Application report for application_1589148979959_0021 (state: ACCEPTED)
20/05/11 09:59:24 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-29-240.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0021), /proxy/application_1589148979959_0021
20/05/11 09:59:24 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/05/11 09:59:24 INFO Client: Application report for application_1589148979959_0021 (state: RUNNING)
20/05/11 09:59:24 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.23.3
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1589191157116
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-29-240.us-east-2.compute.internal:20888/proxy/application_1589148979959_0021/
	 user: hadoop
20/05/11 09:59:24 INFO YarnClientSchedulerBackend: Application application_1589148979959_0021 has started running.
20/05/11 09:59:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43713.
20/05/11 09:59:24 INFO NettyBlockTransferService: Server created on ip-172-31-29-240.us-east-2.compute.internal:43713
20/05/11 09:59:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/05/11 09:59:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 43713, None)
20/05/11 09:59:24 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-29-240.us-east-2.compute.internal:43713 with 1038.8 MB RAM, BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 43713, None)
20/05/11 09:59:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 43713, None)
20/05/11 09:59:24 INFO BlockManager: external shuffle service port = 7337
20/05/11 09:59:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-29-240.us-east-2.compute.internal, 43713, None)
20/05/11 09:59:24 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
20/05/11 09:59:24 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/05/11 09:59:25 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1589148979959_0021
20/05/11 09:59:25 INFO Utils: Using initial executors = 100, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/05/11 09:59:25 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
20/05/11 10:07:45 ERROR TransportClient: Failed to send RPC RPC 7869932238778929974 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:45 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(12,184,Map(ip-172-31-28-249.us-east-2.compute.internal -> 154, ip-172-31-23-3.us-east-2.compute.internal -> 150),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7869932238778929974 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:45 ERROR TransportClient: Failed to send RPC RPC 4958097099396176786 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:45 ERROR YarnScheduler: Lost executor 1 on ip-172-31-23-11.us-east-2.compute.internal: Slave lost
20/05/11 10:07:45 ERROR TransportClient: Failed to send RPC RPC 6130884731673176796 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:45 ERROR YarnScheduler: Lost executor 3 on ip-172-31-22-50.us-east-2.compute.internal: Slave lost
20/05/11 10:07:45 ERROR TransportClient: Failed to send RPC RPC 8812904462621589036 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:45 ERROR YarnScheduler: Lost executor 4 on ip-172-31-28-249.us-east-2.compute.internal: Slave lost
20/05/11 10:07:45 ERROR TransportClient: Failed to send RPC RPC 6529885879186084957 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:45 ERROR YarnScheduler: Lost executor 2 on ip-172-31-23-3.us-east-2.compute.internal: Slave lost
20/05/11 10:07:46 ERROR TransportClient: Failed to send RPC RPC 9153680900896945706 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:46 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(12,184,Map(ip-172-31-28-249.us-east-2.compute.internal -> 154, ip-172-31-23-3.us-east-2.compute.internal -> 150),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 9153680900896945706 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:47 ERROR TransportClient: Failed to send RPC RPC 7814310297808785627 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:47 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(12,184,Map(ip-172-31-28-249.us-east-2.compute.internal -> 154, ip-172-31-23-3.us-east-2.compute.internal -> 150),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7814310297808785627 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:48 ERROR TransportClient: Failed to send RPC RPC 6730496355412121150 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:48 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(12,184,Map(ip-172-31-28-249.us-east-2.compute.internal -> 154, ip-172-31-23-3.us-east-2.compute.internal -> 150),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 6730496355412121150 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:49 ERROR TransportClient: Failed to send RPC RPC 7400043972930303602 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:49 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(12,184,Map(ip-172-31-28-249.us-east-2.compute.internal -> 154, ip-172-31-23-3.us-east-2.compute.internal -> 150),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7400043972930303602 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:50 ERROR TransportClient: Failed to send RPC RPC 7461713599691898723 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:50 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(12,184,Map(ip-172-31-28-249.us-east-2.compute.internal -> 154, ip-172-31-23-3.us-east-2.compute.internal -> 150),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 7461713599691898723 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:51 ERROR TransportClient: Failed to send RPC RPC 8619867556973822591 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:51 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(12,184,Map(ip-172-31-28-249.us-east-2.compute.internal -> 154, ip-172-31-23-3.us-east-2.compute.internal -> 150),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8619867556973822591 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:52 ERROR TransportClient: Failed to send RPC RPC 8386043889234421639 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:52 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(12,184,Map(ip-172-31-28-249.us-east-2.compute.internal -> 154, ip-172-31-23-3.us-east-2.compute.internal -> 150),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8386043889234421639 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:53 ERROR TransportClient: Failed to send RPC RPC 8852296604927747809 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:07:53 ERROR YarnSchedulerBackend$YarnSchedulerEndpoint: Sending RequestExecutors(12,184,Map(ip-172-31-28-249.us-east-2.compute.internal -> 154, ip-172-31-23-3.us-east-2.compute.internal -> 150),Set()) to AM was unsuccessful
java.io.IOException: Failed to send RPC RPC 8852296604927747809 to /172.31.23.3:40400: java.nio.channels.ClosedChannelException
	at org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:362)
	at org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:339)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:987)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:869)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1316)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:730)
	at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1081)
	at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1128)
	at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1070)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
20/05/11 10:09:44 ERROR YarnScheduler: Lost executor 7 on ip-172-31-23-11.us-east-2.compute.internal: Container marked as failed: container_1589148979959_0021_02_000005 on host: ip-172-31-23-11.us-east-2.compute.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.
TERMINATED: No more infectious nodes left to update
Finish simulation: 12
